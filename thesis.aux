\relax 
\citation{a:IBM}
\citation{a:def1}
\citation{a:gartner}
\citation{a:veracity}
\citation{a:https://brightplanet.com/2012/06/structured-vs-unstructured-data/}
\select@language{american}
\@writefile{toc}{\select@language{american}}
\@writefile{lof}{\select@language{american}}
\@writefile{lot}{\select@language{american}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Background}{1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Big Data}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Definition}{1}}
\citation{a:https://brightplanet.com/2012/06/structured-vs-unstructured-data/}
\citation{a:https://jeremyronk.wordpress.com/2014/09/01/structured-semi-structured-and-unstructured-data/}
\citation{a:https://brightplanet.com/2012/06/structured-vs-unstructured-data/}
\citation{a:Beyond the hype}
\citation{a:BigData}
\citation{a:NLP}
\citation{a:analyzer http://www.sbmac.org.br/dincon/trabalhos/PDF/statistics/68066.pdf}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Big Data analytics}{2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2.1}Text analytics}{2}}
\citation{a:https://www.scm.tees.ac.uk/isg/aia/nlp/NLP-overview.pdf}
\citation{a:BigData}
\citation{a:BigData}
\citation{a:mapR}
\citation{a:Akidu}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.3}Big Data Processing Frameworks}{3}}
\citation{a:amazon}
\citation{a:Akidu}
\citation{a:Akidu}
\citation{a:Flink}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.1}The difference between batch and stream processing}{4}}
\citation{a:BigData}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces  Comparison between batch and stream processing dataflows \cite  {a:Flink}}}{5}}
\newlabel{flink}{{1.1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.2}Apache Flink}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces  Flink Stack \cite  {a:BigData}}}{6}}
\newlabel{flink}{{1.2}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Flink Architecture Overview}}{6}}
\newlabel{archi}{{1.3}{6}}
\citation{transf}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Flink Streaming dataflow}}{7}}
\newlabel{dataflow}{{1.4}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces  Tumbling windows}}{8}}
\newlabel{win1}{{1.5}{8}}
\citation{a:Spark1}
\citation{a:Spark2}
\citation{a:Spark2}
\citation{a:Spark3}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces  Sliding windows}}{9}}
\newlabel{win2}{{1.6}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.3}Apache Spark}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces The components of the Spark Stack}}{9}}
\newlabel{stack}{{1.7}{9}}
\citation{a:Spark1}
\citation{a:comp}
\citation{wc}
\citation{wc}
\citation{wc}
\citation{wc}
\citation{wc}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces The components of a distributed Spark application\cite  {a:Spark2}}}{10}}
\newlabel{spark}{{1.8}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3.4}Performance comparison between Apache Spark and Apache Flink}{10}}
\citation{a:ML}
\citation{a:Tom:MachineLearning}
\citation{a:ML}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Machine Learning}{11}}
\citation{a:labelprop}
\citation{a:comm}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.1}Unsupervised Learning}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1.1}Label Propagation Algorithm}{12}}
\citation{a:kmeansExple}
\citation{a:silhouette}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1.2}Kmeans}{13}}
\newlabel{kmeans}{{1.2.1.2}{13}}
\newlabel{SilEq}{{1.1}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Initial graph}}{13}}
\newlabel{lpa}{{1.9}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces First Iteration}}{13}}
\newlabel{lpa}{{1.10}{13}}
\citation{a:colt92}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Final Iteration}}{14}}
\newlabel{lpa}{{1.11}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces KMeans clustering example\cite  {a:kmeansExple}}}{14}}
\newlabel{expl1}{{1.12}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2.2}Supervised Learning}{14}}
\citation{a:SvmSlides}
\citation{a:Nello:Svm}
\citation{a:Tom:MachineLearning}
\citation{a:Nello:Svm}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Workflow of a classification example}}{15}}
\newlabel{ref}{{1.13}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2.1}Logistic Regression}{15}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2.2}Support Vector Machines}{15}}
\newlabel{svmSection}{{1.2.2.2}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.14}{\ignorespaces Linear Support Vector Machines \cite  {a:SvmSlides}}}{16}}
\newlabel{svm}{{1.14}{16}}
\citation{a:tfidf}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}State of the Art}{17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Concept Detection in Text Datasets}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}TFIDF based approaches}{17}}
\citation{a:ck}
\citation{a:udos}
\citation{a:udos}
\citation{a:udos}
\citation{a:def}
\citation{a:ont}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Ontology based approaches}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.1}What is an ontology?}{19}}
\citation{a:ont}
\citation{a:ont}
\citation{standford}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.2}Ontology based method for topic identification of learning materials}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Domain Ontology of the subject Computer Science \cite  {a:ont}}}{20}}
\newlabel{ont}{{2.1}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Workflow of the topic extraction process \cite  {a:ont}}}{21}}
\newlabel{workfow}{{2.2}{21}}
\citation{a:ont2}
\citation{a:kmeans}
\citation{a:Huang2008}
\citation{a:b}
\citation{a:Daud2010}
\citation{a:vsm}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.3}A Wikipedia ontology based approach for automatic topic identification}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Machine learning based approaches}{22}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3.1}Kmeans based Algorithm}{22}}
\citation{a:yangcomp}
\citation{a:yangcomp}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Architecture for Topic Detection Prototype System}}{23}}
\newlabel{proto}{{2.3}{23}}
\citation{a:tdtmetric}
\citation{a:tdtmetric}
\citation{a:arabic}
\citation{a:arabic}
\citation{liga}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Graph based approaches}{25}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces LIGA Approach workflow}}{25}}
\newlabel{liga}{{2.4}{25}}
\citation{a:wiki}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Topic graph example}}{26}}
\newlabel{topic}{{2.5}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Word Path example}}{26}}
\newlabel{path}{{2.6}{26}}
\citation{a:inter}
\citation{a:parser}
\citation{a:concept}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Concept Detection in Image Datasets}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Lexical graph}}{27}}
\newlabel{lexical}{{2.7}{27}}
\citation{a:rcnn}
\citation{a:J. Uijlings}
\citation{K. van de Sande}
\citation{T. Gevers}
\citation{and A. Smeulders. Selective search for object recognition.IJCV}
\citation{2013.}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Semantic Meta-model}}{28}}
\newlabel{model}{{2.8}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Interpreted Graph}}{28}}
\newlabel{sem}{{2.9}{28}}
\citation{a:online}
\citation{a:ella}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Expanded Semantic Graph of the query}}{29}}
\newlabel{exp}{{2.10}{29}}
\citation{a:stem}
\citation{a:lemma}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Contribution}{31}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Preprocessing}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Approach}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Model construction and learning}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Training graph}}{32}}
\newlabel{fig:trainingGraph}{{3.1}{32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Model testing}{32}}
\bibstyle{plain}
\bibdata{all_publications}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Testing graph}}{i}}
\newlabel{fig:trainingGraph}{{3.2}{i}}
\bibcite{a:gartner}{1}
\bibcite{a:def1}{2}
\bibcite{a:IBM}{3}
\bibcite{a:veracity}{4}
\bibcite{a:Akidu}{5}
\bibcite{a:NLP}{6}
\bibcite{a:wiki}{7}
\bibcite{a:Nello:Svm}{8}
\bibcite{a:rcnn}{9}
\bibcite{a:Daud2010}{10}
\bibcite{a:b}{11}
\bibcite{a:inter}{12}
\bibcite{a:ella}{13}
\bibcite{a:ML}{14}
\bibcite{a:udos}{15}
\bibcite{a:ck}{16}
\bibcite{a:Spark3}{17}
\bibcite{a:Spark1}{18}
\bibcite{a:Huang2008}{19}
\bibcite{a:BigData}{20}
\bibcite{a:ont2}{21}
\bibcite{a:comm}{22}
\bibcite{a:kmeansExple}{23}
\bibcite{a:Tom:MachineLearning}{24}
\bibcite{a:SvmSlides}{25}
\bibcite{a:tdtmetric}{26}
\bibcite{a:ont}{27}
\bibcite{a:online}{28}
\bibcite{a:colt92}{29}
\bibcite{a:tfidf}{30}
\bibcite{a:vsm}{31}
\bibcite{a:Flink}{32}
\bibcite{a:Spark2}{33}
\bibcite{a:arabic}{34}
\bibcite{a:amazon}{35}
\bibcite{a:labelprop}{36}
\bibcite{a:yangcomp}{37}
